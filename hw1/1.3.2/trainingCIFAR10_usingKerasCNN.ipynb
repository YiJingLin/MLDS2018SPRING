{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 30\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of params:  79688\n",
      "# of params:  154238\n",
      "# of params:  229292\n",
      "# of params:  304850\n",
      "# of params:  457478\n",
      "# of params:  612122\n",
      "# of params:  768782\n",
      "# of params:  927458\n",
      "# of params:  1088150\n",
      "# of params:  1250858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.models.Sequential at 0x7f1940ad5588>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def VGG(n_ly1, n_ly2):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(n_ly1, (3, 3), padding='same',\n",
    "                     input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(n_ly1, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(n_ly2, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(n_ly2, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "#     print(\"# of params: \", model.count_params())\n",
    "    return model\n",
    "\n",
    "# check # of params curve\n",
    "\n",
    "VGG(2, 4)\n",
    "VGG(4, 8)\n",
    "VGG(6, 12)\n",
    "VGG(8, 16)\n",
    "VGG(12, 24)\n",
    "VGG(16, 32)\n",
    "VGG(20, 40)\n",
    "VGG(24, 48)\n",
    "VGG(28, 56)\n",
    "VGG(32, 64)\n",
    "\n",
    "# [2, 4, 6, 8, 12, 16, 20, 24, 28, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = {}\n",
    "\n",
    "result['param_num'] = []\n",
    "result['train_acc'] = []\n",
    "result['test_acc'] = []\n",
    "result['train_loss'] = []\n",
    "result['test_loss'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of params:  154238\n",
      "***itr:  0   |  params:  154238\n",
      "train_acc : 0.5645 \t test_acc : 0.5495 \t train_loss : 1.2565 \t test_loss : 1.2717\n",
      "# of params:  229292\n",
      "***itr:  1   |  params:  229292\n",
      "train_acc : 0.5742 \t test_acc : 0.5639 \t train_loss : 1.2297 \t test_loss : 1.2542\n",
      "# of params:  304850\n",
      "***itr:  2   |  params:  304850\n",
      "train_acc : 0.6427 \t test_acc : 0.6229 \t train_loss : 1.0408 \t test_loss : 1.0859\n",
      "# of params:  457478\n",
      "***itr:  3   |  params:  457478\n",
      "train_acc : 0.7116 \t test_acc : 0.6845 \t train_loss : 0.8435 \t test_loss : 0.9109\n",
      "# of params:  612122\n",
      "***itr:  4   |  params:  612122\n",
      "train_acc : 0.7101 \t test_acc : 0.6741 \t train_loss : 0.8399 \t test_loss : 0.9322\n",
      "# of params:  768782\n",
      "***itr:  5   |  params:  768782\n",
      "train_acc : 0.7590 \t test_acc : 0.7212 \t train_loss : 0.7129 \t test_loss : 0.8124\n",
      "# of params:  927458\n",
      "***itr:  6   |  params:  927458\n",
      "train_acc : 0.7870 \t test_acc : 0.7498 \t train_loss : 0.6291 \t test_loss : 0.7425\n",
      "# of params:  1088150\n",
      "***itr:  7   |  params:  1088150\n",
      "train_acc : 0.7843 \t test_acc : 0.7391 \t train_loss : 0.6432 \t test_loss : 0.7810\n",
      "# of params:  1250858\n",
      "***itr:  8   |  params:  1250858\n",
      "train_acc : 0.8252 \t test_acc : 0.7679 \t train_loss : 0.5576 \t test_loss : 0.6854\n"
     ]
    }
   ],
   "source": [
    "layParam = [4, 6, 8, 12, 16, 20, 24, 28, 32]\n",
    "for itr, params in enumerate(layParam):\n",
    "    \n",
    "    model = VGG(params, params*2)\n",
    "    print('***itr: ', itr, '  |  params: ', model.count_params())\n",
    "    # initiate RMSprop optimizer\n",
    "    opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "    # Let's train the model using RMSprop\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=30,\n",
    "                  validation_data=(x_test, y_test),\n",
    "                  verbose = 0,\n",
    "    shuffle=True)\n",
    "\n",
    "    score = model.evaluate(x_train, y_train, verbose=0)\n",
    "    train_loss, train_acc = score\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    test_loss, test_acc = score\n",
    "\n",
    "\n",
    "    result['param_num'].append(round(model.count_params(), 4))\n",
    "    result['train_acc'].append(round(train_acc, 4))\n",
    "    result['test_acc'].append(round(test_acc, 4))\n",
    "    result['train_loss'].append(round(train_loss, 4))\n",
    "    result['test_loss'].append(round(test_loss, 4))\n",
    "\n",
    "    ### print\n",
    "    print(\n",
    "        'train_acc : %.4f' % train_acc,\n",
    "        '\\t test_acc : %.4f' % test_acc,\n",
    "        '\\t train_loss : %.4f' % train_loss,\n",
    "        '\\t test_loss : %.4f' % test_loss,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'param_num': [79688,\n",
       "  154238,\n",
       "  229292,\n",
       "  304850,\n",
       "  457478,\n",
       "  612122,\n",
       "  768782,\n",
       "  927458,\n",
       "  1088150,\n",
       "  1250858],\n",
       " 'test_acc': [0.43590000000000001,\n",
       "  0.54949999999999999,\n",
       "  0.56389999999999996,\n",
       "  0.62290000000000001,\n",
       "  0.6845,\n",
       "  0.67410000000000003,\n",
       "  0.72119999999999995,\n",
       "  0.74980000000000002,\n",
       "  0.73909999999999998,\n",
       "  0.76790000000000003],\n",
       " 'test_loss': [1.5630999999999999,\n",
       "  1.2717000000000001,\n",
       "  1.2542,\n",
       "  1.0859000000000001,\n",
       "  0.91090000000000004,\n",
       "  0.93220000000000003,\n",
       "  0.81240000000000001,\n",
       "  0.74250000000000005,\n",
       "  0.78100000000000003,\n",
       "  0.68540000000000001],\n",
       " 'train_acc': [0.43319999999999997,\n",
       "  0.5645,\n",
       "  0.57420000000000004,\n",
       "  0.64270000000000005,\n",
       "  0.71160000000000001,\n",
       "  0.71009999999999995,\n",
       "  0.75900000000000001,\n",
       "  0.78700000000000003,\n",
       "  0.7843,\n",
       "  0.82520000000000004],\n",
       " 'train_loss': [1.5609,\n",
       "  1.2565,\n",
       "  1.2297,\n",
       "  1.0407999999999999,\n",
       "  0.84350000000000003,\n",
       "  0.83989999999999998,\n",
       "  0.71289999999999998,\n",
       "  0.62909999999999999,\n",
       "  0.64319999999999999,\n",
       "  0.55759999999999998]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./output/result_CIFAR10.pkl\", \"wb\") as file:\n",
    "    pickle.dump(result, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
